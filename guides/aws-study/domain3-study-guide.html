
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS AI Practitioner - Domain 3: Applications of Foundation Models</title>
    <link rel="stylesheet" href="../style.css">

    <script>
      
      const files = {
        
      }
    


      window.fs = {}
      window.fs.readFile = (fileName) => {
        // return array buffer
        return new Promise((resolve) => {
          const content = files[fileName]
          const decoded = atob(content)
          const arr = new Uint8Array(decoded.length)
          for (let i = 0; i < decoded.length; i++) {
            arr[i] = decoded.charCodeAt(i)
          }
          resolve(arr)
        })
      }

      // stub out window.user.get, window.db.get and window.db.set so that it works when you download the html doc
      window.db = {}
      window.db.get = (key) => {
        // use localStorage to store the artifact
        const value = localStorage.getItem(key)
        if (value) {
          return JSON.parse(value)
        }

        return null
      }

      window.db.set = (key, value) => {
        // use localStorage to store the artifact
        localStorage.setItem(key, JSON.stringify(value))
      }

      window.user = {}
      window.user.get = () => {
        return {
          userId: "user-id-placeholder",
          email: "placeholder@test.com"
        }
      }

    </script>
    </head>
<body>
    <div class="container">
        <div class="header">
            <h1>üöÄ Domain 3: Applications of Foundation Models</h1>
            <p>AWS AI Practitioner Certification Study Guide</p>
            <div class="progress-bar">
                <div class="progress-fill" id="progressFill"></div>
            </div>
            <p><strong>Weight: 28% of exam</strong> | <strong>Study Time: 4-5 weeks</strong></p>
        </div>

        <div class="domain-overview">
            <h2>üìã Domain Overview</h2>
            <p><strong>Purpose:</strong> This is the highest-weighted domain, focusing on practical implementation of foundation models in real-world applications. It covers design considerations, prompt engineering, training/fine-tuning, and performance evaluation.</p>
            <p><strong>Focus Areas:</strong> Application design, prompt optimization, model customization, performance evaluation, and deployment strategies.</p>
            <p><strong>Depth Level:</strong> Hands-on implementation knowledge with deep understanding of AWS services and best practices.</p>
        </div>

        <!-- Task Statement 3.1 -->
        <div class="task-statement">
            <div class="task-header" onclick="toggleTask('task1')">
                <h3>Task Statement 3.1: Describe Design Considerations for Applications that Use Foundation Models</h3>
                <button class="toggle-btn" id="toggle1">‚ñº</button>
            </div>
            <div class="task-content" id="task1">
                <div class="objectives">
                    <h4>üéØ Learning Objectives:</h4>
                    <ul>
                        <li>Understand architectural patterns for foundation model applications</li>
                        <li>Identify design considerations for scalability, latency, and cost</li>
                        <li>Recognize security and compliance requirements</li>
                        <li>Understand integration patterns with existing systems</li>
                    </ul>
                </div>

                <h4>üèóÔ∏è Application Architecture Patterns</h4>
                <div class="concept-grid">
                    <div class="concept-card">
                        <h5>Direct API Integration</h5>
                        <p>Simple applications that directly call foundation model APIs</p>
                        <p><strong>Use Cases:</strong> Chatbots, content generation tools, simple Q&A systems</p>
                        <p><strong>AWS Services:</strong> Bedrock API, Lambda functions, API Gateway</p>
                        <p><strong>Pros:</strong> Low latency, simple implementation</p>
                        
                        <p><strong>Cons:</strong> Limited customization, dependency on model availability</p>
                    </div>
                    <div class="concept-card">
                        <h5>Retrieval Augmented Generation (RAG)</h5>
                        <p>Combines foundation models with external knowledge sources</p>
                        <p><strong>Components:</strong> Vector database, embedding models, retrieval logic</p>
                        <p><strong>AWS Services:</strong> OpenSearch, Bedrock, Kendra, S3</p>
                        <p><strong>Benefits:</strong> Up-to-date information, domain-specific knowledge</p>
                        <p><strong>Complexity:</strong> Higher implementation and maintenance overhead</p>
                    </div>
                    <div class="concept-card">
                        <h5>Fine-tuned Model Deployment</h5>
                        <p>Custom-trained models deployed on dedicated infrastructure</p>
                        <p><strong>Use Cases:</strong> Domain-specific tasks, proprietary data, performance optimization</p>
                        <p><strong>AWS Services:</strong> SageMaker endpoints, Bedrock custom models</p>
                        <p><strong>Benefits:</strong> Optimized performance, custom behavior</p>
                        <p><strong>Considerations:</strong> Higher cost, longer development time</p>
                    </div>
                    <div class="concept-card">
                        <h5>Multi-Agent Systems</h5>
                        <p>Multiple specialized models working together in workflows</p>
                        <p><strong>Orchestration:</strong> Step Functions, EventBridge, SQS</p>
                        <p><strong>Use Cases:</strong> Complex document processing, multi-step analysis</p>
                        <p><strong>Benefits:</strong> Specialized capabilities, fault tolerance</p>
                        <p><strong>Challenges:</strong> Coordination complexity, error handling</p>
                    </div>
                </div>

                <div class="visual-placeholder">
                    <h4>üèóÔ∏è Recommended Visual: Architecture Decision Tree</h4>
                    <p>Create a decision flowchart: Simple Use Case ‚Üí Direct API | Need Domain Knowledge ‚Üí RAG | Need Custom Behavior ‚Üí Fine-tuning | Complex Workflow ‚Üí Multi-Agent</p>
                </div>

                <h4>üìä Design Considerations Matrix</h4>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Consideration</th>
                            <th>Direct API</th>
                            <th>RAG</th>
                            <th>Fine-tuned</th>
                            <th>Multi-Agent</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Development Time</strong></td>
                            <td>Low</td>
                            <td>Medium</td>
                            <td>High</td>
                            <td>Very High</td>
                        </tr>
                        <tr>
                            <td><strong>Cost</strong></td>
                            <td>Low-Medium</td>
                            <td>Medium</td>
                            <td>High</td>
                            <td>Variable</td>
                        </tr>
                        <tr>
                            <td><strong>Latency</strong></td>
                            <td>Low</td>
                            <td>Medium</td>
                            <td>Low-Medium</td>
                            <td>High</td>
                        </tr>
                        <tr>
                            <td><strong>Customization</strong></td>
                            <td>Low</td>
                            <td>Medium</td>
                            <td>High</td>
                            <td>Very High</td>
                        </tr>
                        <tr>
                            <td><strong>Scalability</strong></td>
                            <td>High</td>
                            <td>Medium</td>
                            <td>Medium</td>
                            <td>Complex</td>
                        </tr>
                    </tbody>
                </table>

                <h4>üîí Security & Compliance Considerations</h4>
                <div class="concept-grid">
                    <div class="concept-card">
                        <h5>Data Privacy</h5>
                        <p><strong>Concerns:</strong> Sensitive data in prompts, model training data</p>
                        <p><strong>Solutions:</strong> Data anonymization, private endpoints, encryption</p>
                        <p><strong>AWS Tools:</strong> VPC endpoints, KMS encryption, IAM policies</p>
                    </div>
                    <div class="concept-card">
                        <h5>Model Security</h5>
                        <p><strong>Threats:</strong> Prompt injection, data extraction, model poisoning</p>
                        <p><strong>Mitigations:</strong> Input validation, output filtering, guardrails</p>
                        <p><strong>AWS Features:</strong> Bedrock Guardrails, WAF, CloudTrail</p>
                    </div>
                    <div class="concept-card">
                        <h5>Compliance Requirements</h5>
                        <p><strong>Standards:</strong> GDPR, HIPAA, SOC 2, PCI DSS</p>
                        <p><strong>Considerations:</strong> Data residency, audit trails, access controls</p>
                        <p><strong>AWS Support:</strong> Compliance certifications, Config, CloudTrail</p>
                    </div>
                    <div class="concept-card">
                        <h5>Intellectual Property</h5>
                        <p><strong>Concerns:</strong> Code generation, content ownership, training data rights</p>
                        <p><strong>Protections:</strong> Usage agreements, output review, attribution</p>
                        <p><strong>Best Practices:</strong> Clear policies, human oversight, documentation</p>
                    </div>
                </div>

                <div class="aws-services">
                    <h4>üîß Key AWS Services for Application Design</h4>
                    <div class="service-grid">
                        <div class="service-item">
                            <strong>Amazon Bedrock</strong><br>
                            Foundation model APIs with built-in security and compliance features
                        </div>
                        <div class="service-item">
                            <strong>API Gateway</strong><br>
                            Managed API endpoints with throttling, authentication, and monitoring
                        </div>
                        <div class="service-item">
                            <strong>Lambda</strong><br>
                            Serverless compute for application logic and model orchestration
                        </div>
                        <div class="service-item">
                            <strong>Step Functions</strong><br>
                            Workflow orchestration for complex multi-step AI processes
                        </div>
                        <div class="service-item">
                            <strong>OpenSearch</strong><br>
                            Vector search capabilities for RAG implementations
                        </div>
                        <div class="service-item">
                            <strong>CloudFront</strong><br>
                            Content delivery and caching for AI-generated content
                        </div>
                    </div>
                </div>

                <div class="hands-on">
                    <h4>üõ†Ô∏è Hands-On Practice</h4>
                    <ul>
                        <li><strong>Architecture Design:</strong> Design a RAG system for document Q&A</li>
                        <li><strong>Security Implementation:</strong> Set up VPC endpoints for Bedrock</li>
                        <li><strong>Cost Analysis:</strong> Compare costs of different architectural patterns</li>
                        <li><strong>Performance Testing:</strong> Measure latency for various model configurations</li>
                        <li><strong>Compliance Setup:</strong> Configure CloudTrail for AI service auditing</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Task Statement 3.2 -->
        <div class="task-statement">
            <div class="task-header" onclick="toggleTask('task2')">
                <h3>Task Statement 3.2: Choose Effective Prompt Engineering Techniques</h3>
                <button class="toggle-btn" id="toggle2">‚ñº</button>
            </div>
            <div class="task-content" id="task2">
                <div class="objectives">
                    <h4>üéØ Learning Objectives:</h4>
                    <ul>
                        <li>Master various prompt engineering techniques and patterns</li>
                        <li>Understand when to apply different prompting strategies</li>
                        <li>Optimize prompts for specific use cases and models</li>
                        <li>Implement prompt templates and dynamic prompting</li>
                    </ul>
                </div>

                <h4>üéØ Core Prompt Engineering Techniques</h4>
                <div class="technique-card">
                    <h5>Zero-Shot Prompting</h5>
                    <p>Providing a task description without examples, relying on the model's pre-trained knowledge.</p>
                    <div class="prompt-example">
                        <span class="prompt-label">Prompt:</span> "Translate the following English text to French: 'Hello, how are you today?'"<br><br>
                        <span class="response-label">Response:</span> "Bonjour, comment allez-vous aujourd'hui ?"
                    </div>
                    <p><strong>Best For:</strong> Simple, well-defined tasks that models are trained for</p>
                    <p><strong>AWS Context:</strong> Works well with most Bedrock models for common tasks</p>
                </div>

                <div class="technique-card">
                    <h5>Few-Shot Prompting</h5>
                    <p>Providing a few examples of the desired input-output pattern before the actual task.</p>
                    <div class="prompt-example">
                        <span class="prompt-label">Prompt:</span> "Classify the sentiment of these reviews:<br>
                        Review: 'The product is amazing!' Sentiment: Positive<br>
                        Review: 'Terrible quality, waste of money.' Sentiment: Negative<br>
                        Review: 'The service was excellent and fast.' Sentiment:"<br><br>
                        <span class="response-label">Response:</span> "Positive"
                    </div>
                    <p><strong>Best For:</strong> Complex tasks, specific formats, domain-specific applications</p>
                    <p><strong>Optimization:</strong> 3-5 examples usually optimal, diverse examples improve performance</p>
                </div>

                <div class="technique-card">
                    <h5>Chain-of-Thought (CoT) Prompting</h5>
                    <p>Encouraging the model to show its reasoning process step-by-step.</p>
                    <div class="prompt-example">
                        <span class="prompt-label">Prompt:</span> "Solve this step by step: If a store has 15 apples and sells 7, then receives a shipment of 12 more apples, how many apples does the store have now?"<br><br>
                        <span class="response-label">Response:</span> "Let me solve this step by step:<br>
                        1. Starting apples: 15<br>
                        2. Apples sold: 7<br>
                        3. Remaining after sale: 15 - 7 = 8<br>
                        4. New shipment: 12<br>
                        5. Final total: 8 + 12 = 20 apples"
                    </div>
                    <p><strong>Best For:</strong> Mathematical problems, logical reasoning, complex analysis</p>
                    <p><strong>Trigger Phrases:</strong> "Let's think step by step", "Solve this step by step"</p>
                </div>

                <div class="technique-card">
                    <h5>Role-Based Prompting</h5>
                    <p>Assigning a specific role or persona to the model to guide its responses.</p>
                    <div class="prompt-example">
                        <span class="prompt-label">Prompt:</span> "You are a senior AWS solutions architect. Explain the benefits of using Amazon Bedrock for a startup building a customer service chatbot."<br><br>
                        <span class="response-label">Response:</span> "As a solutions architect, I'd recommend Bedrock for several key reasons: managed infrastructure reduces operational overhead, pay-per-use pricing aligns with startup budgets, multiple model options allow experimentation..."
                    </div>
                    <p><strong>Effective Roles:</strong> Expert, teacher, analyst, critic, creative writer</p>
                    <p><strong>Benefits:</strong> More focused responses, appropriate tone and style</p>
                </div>

                <h4>üîß Advanced Prompting Strategies</h4>
                <div class="concept-grid">
                    <div class="concept-card">
                        <h5>Template-Based Prompting</h5>
                        <p>Using structured templates with placeholders for dynamic content</p>
                        <p><strong>Example:</strong> "Analyze the {document_type} for {specific_aspect} and provide {output_format}"</p>
                        <p><strong>Benefits:</strong> Consistency, reusability, easier testing</p>
                        <p><strong>AWS Implementation:</strong> Parameter Store, Lambda environment variables</p>
                    </div>
                    <div class="concept-card">
                        <h5>Iterative Refinement</h5>
                        <p>Progressively refining prompts based on model outputs</p>
                        <p><strong>Process:</strong> Initial prompt ‚Üí Analyze output ‚Üí Identify issues ‚Üí Refine prompt</p>
                        <p><strong>Tools:</strong> A/B testing, version control, performance metrics</p>
                        <p><strong>AWS Support:</strong> SageMaker Experiments, CloudWatch metrics</p>
                    </div>
                    <div class="concept-card">
                        <h5>Context Window Optimization</h5>
                        <p>Efficiently using available context space for maximum effectiveness</p>
                        <p><strong>Strategies:</strong> Prioritize important information, use compression techniques</p>
                        <p><strong>Considerations:</strong> Token limits, cost implications, performance impact</p>
                        <p><strong>Monitoring:</strong> Track token usage and costs</p>
                    </div>
                    <div class="concept-card">
                        <h5>Multi-Turn Conversations</h5>
                        <p>Maintaining context across multiple interactions</p>
                        <p><strong>Challenges:</strong> Context management, memory limitations, state tracking</p>
                        <p><strong>Solutions:</strong> Session storage, context summarization, conversation history</p>
                        <p><strong>AWS Services:</strong> DynamoDB, ElastiCache, S3</p>
                    </div>
                </div>

                <div class="visual-placeholder">
                    <h4>üìä Recommended Visual: Prompt Engineering Decision Matrix</h4>
                    <p>Create a matrix showing Task Complexity (Simple/Complex) vs Available Examples (None/Few/Many) with recommended techniques in each quadrant.</p>
                </div>

                <h4>üéØ Model-Specific Considerations</h4>
                <div class="model-selection-matrix">
                    <div class="model-option">
                        <h6>Anthropic Claude</h6>
                        <p><strong>Strengths:</strong> Long context, reasoning, safety</p>
                        <p><strong>Prompt Style:</strong> Conversational, detailed instructions</p>
                        <p><strong>Best Techniques:</strong> Chain-of-thought, role-based prompting</p>
                        <div>
                            <span class="performance-indicator performance-high">Reasoning</span>
                            <span class="performance-indicator performance-high">Safety</span>
                            <span class="performance-indicator performance-medium">Speed</span>
                        </div>
                    </div>
                    <div class="model-option">
                        <h6>Amazon Titan</h6>
                        <p><strong>Strengths:</strong> Cost-effective, general purpose</p>
                        <p><strong>Prompt Style:</strong> Clear, concise instructions</p>
                        <p><strong>Best Techniques:</strong> Zero-shot, few-shot for simple tasks</p>
                        <div>
                            <span class="performance-indicator performance-high">Cost</span>
                            <span class="performance-indicator performance-medium">Reasoning</span>
                            <span class="performance-indicator performance-high">Speed</span>
                        </div>
                    </div>
                    <div class="model-option">
                        <h6>AI21 Jurassic</h6>
                        <p><strong>Strengths:</strong> Multilingual, instruction following</p>
                        <p><strong>Prompt Style:</strong> Structured, explicit instructions</p>
                        <p><strong>Best Techniques:</strong> Template-based, role prompting</p>
                        <div>
                            <span class="performance-indicator performance-high">Multilingual</span>
                            <span class="performance-indicator performance-medium">Reasoning</span>
                            <span class="performance-indicator performance-medium">Cost</span>
                        </div>
                    </div>
                    <div class="model-option">
                        <h6>Cohere Command</h6>
                        <p><strong>Strengths:</strong> RAG optimization, citations</p>
                        <p><strong>Prompt Style:</strong> Structured queries with context</p>
                        <p><strong>Best Techniques:</strong> RAG-enhanced prompting, citation requests</p>
                        <div>
                            <span class="performance-indicator performance-high">RAG</span>
                            <span class="performance-indicator performance-high">Citations</span>
                            <span class="performance-indicator performance-medium">General</span>
                        </div>
                    </div>
                </div>

                <div class="aws-services">
                    <h4>üîß AWS Tools for Prompt Engineering</h4>
                    <div class="service-grid">
                        <div class="service-item">
                            <strong>Bedrock Playground</strong><br>
                            Interactive environment for testing and refining prompts
                        </div>
                        <div class="service-item">
                            <strong>SageMaker Studio</strong><br>
                            Notebook environment for prompt experimentation and analysis
                        </div>
                        <div class="service-item">
                            <strong>Parameter Store</strong><br>
                            Centralized storage for prompt templates and configurations
                        </div>
                        <div class="service-item">
                            <strong>CloudWatch</strong><br>
                            Monitoring prompt performance and token usage metrics
                        </div>
                    </div>
                </div>

                <div class="hands-on">
                    <h4>üõ†Ô∏è Hands-On Practice</h4>
                    <ul>
                        <li><strong>Prompt Comparison:</strong> Test the same task with different prompting techniques</li>
                        <li><strong>Model Testing:</strong> Compare how different models respond to the same prompts</li>
                        <li><strong>Template Development:</strong> Create reusable prompt templates for common tasks</li>
                        <li><strong>Performance Optimization:</strong> Measure and optimize token usage and response quality</li>
                        <li><strong>A/B Testing:</strong> Set up experiments to compare prompt variations</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Task Statement 3.3 -->
        <div class="task-statement">
            <div class="task-header" onclick="toggleTask('task3')">
                <h3>Task Statement 3.3: Describe the Training and Fine-tuning Process for Foundation Models</h3>
                <button class="toggle-btn" id="toggle3">‚ñº</button>
            </div>
            <div class="task-content" id="task3">
                <div class="objectives">
                    <h4>üéØ Learning Objectives:</h4>
                    <ul>
                        <li>Understand the complete model training lifecycle</li>
                        <li>Distinguish between pre-training, fine-tuning, and other adaptation methods</li>
                        <li>Identify when and how to implement fine-tuning on AWS</li>
                        <li>Understand cost, time, and resource considerations</li>
                    </ul>
                </div>

                <h4>üîÑ Foundation Model Training Lifecycle</h4>
                <div class="architecture-container">
                    <div class="architecture-step">
                        <h5>Pre-training Phase</h5>
                        <p><strong>Purpose:</strong> Train base model on large, diverse datasets to learn general language patterns</p>
                        <p><strong>Data:</strong> Billions of tokens from books, web pages, articles, code repositories</p>
                        <p><strong>Duration:</strong> Weeks to months with massive compute resources</p>
                        <p><strong>Cost:</strong> Millions of dollars for large models</p>
                        <p><strong>AWS Context:</strong> Typically done by model providers (Anthropic, AI21, etc.)</p>
                    </div>
                    <div class="architecture-step">
                        <h5>Instruction Tuning</h5>
                        <p><strong>Purpose:</strong> Teach model to follow instructions and respond helpfully</p>
                        <p><strong>Data:</strong> Instruction-response pairs, task-specific examples</p>
                        <p><strong>Techniques:</strong> Supervised fine-tuning on curated datasets</p>
                        <p><strong>Outcome:</strong> Model that can understand and execute various tasks</p>
                    </div>
                    <div class="architecture-step">
                        <h5>Alignment Training (RLHF)</h5>
                        <p><strong>Purpose:</strong> Align model behavior with human preferences and values</p>
                        <p><strong>Method:</strong> Reinforcement Learning from Human Feedback</p>
                        <p><strong>Process:</strong> Human rating ‚Üí Reward model training ‚Üí Policy optimization</p>
                        <p><strong>Goals:</strong> Helpful, harmless, honest responses</p>
                    </div>
                    <div class="architecture-step">
                        <h5>Domain-Specific Fine-tuning</h5>
                        <p><strong>Purpose:</strong> Adapt model for specific domains, tasks, or organizations</p>
                        <p><strong>Data:</strong> Domain-specific datasets, proprietary information</p>
                        <p><strong>AWS Services:</strong> Bedrock custom models, SageMaker training jobs</p>
                        <p><strong>Benefits:</strong> Improved performance on specific tasks, custom behavior</p>
                    </div>
                </div>

                <h4>üéØ Fine-tuning Approaches and When to Use Them</h4>
                <div class="concept-grid">
                    <div class="concept-card">
                        <h5>Full Fine-tuning</h5>
                        <p>Updating all model parameters with new data</p>
                        <p><strong>When to Use:</strong> Large datasets, significant domain shift, maximum performance needed</p>
                        <p><strong>Requirements:</strong> Substantial compute resources, large datasets (10K+ examples)</p>
                        <p><strong>AWS Implementation:</strong> SageMaker training jobs with GPU instances</p>
                        <p><strong>Cost:</strong> High - requires significant compute time and resources</p>
                    </div>
                    <div class="concept-card">
                        <h5>Parameter-Efficient Fine-tuning (PEFT)</h5>
                        <p>Updating only a small subset of model parameters</p>
                        <p><strong>Techniques:</strong> LoRA (Low-Rank Adaptation), Adapters, Prefix tuning</p>
                        <p><strong>Benefits:</strong> Lower compute cost, faster training, reduced storage</p>
                        <p><strong>Trade-offs:</strong> Potentially lower performance than full fine-tuning</p>
                        <p><strong>AWS Support:</strong> Available in SageMaker JumpStart</p>
                    </div>
                    <div class="concept-card">
                        <h5>In-Context Learning</h5>
                        <p>Providing examples within the prompt without updating model parameters</p>
                        <p><strong>Advantages:</strong> No training required, immediate results, easy to iterate</p>
                        <p><strong>Limitations:</strong> Context window limits, higher inference costs</p>
                        <p><strong>Best For:</strong> Quick experimentation, small datasets, dynamic examples</p>
                        <p><strong>AWS Implementation:</strong> Direct Bedrock API calls with examples</p>
                    </div>
                    <div class="concept-card">
                        <h5>Retrieval Augmented Generation (RAG)</h5>
                        <p>Enhancing model responses with retrieved external information</p>
                        <p><strong>Components:</strong> Vector database, embedding model, retrieval system</p>
                        <p><strong>Benefits:</strong> Up-to-date information, no model retraining needed</p>
                        <p><strong>Use Cases:</strong> Knowledge bases, document Q&A, dynamic information</p>
                        <p><strong>AWS Stack:</strong> OpenSearch + Bedrock + Lambda</p>
                    </div>
                </div>

                <div class="visual-placeholder">
                    <h4>üìä Recommended Visual: Fine-tuning Decision Tree</h4>
                    <p>Create a decision tree: Data Size ‚Üí Training Budget ‚Üí Performance Requirements ‚Üí Recommended Approach (In-Context/RAG/PEFT/Full Fine-tuning)</p>
                </div>

                <h4>‚öñÔ∏è Approach Comparison Matrix</h4>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Approach</th>
                            <th>Data Required</th>
                            <th>Training Time</th>
                            <th>Cost</th>
                            <th>Performance</th>
                            <th>Flexibility</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>In-Context Learning</strong></td>
                            <td>Few examples</td>
                            <td>None</td>
                            <td>Low</td>
                            <td>Good</td>
                            <td>High</td>
                        </tr>
                        <tr>
                            <td><strong>RAG</strong></td>
                            <td>Knowledge base</td>
                            <td>Setup only</td>
                            <td>Low-Medium</td>
                            <td>Very Good</td>
                            <td>High</td>
                        </tr>
                        <tr>
                            <td><strong>PEFT</strong></td>
                            <td>1K-10K examples</td>
                            <td>Hours-Days</td>
                            <td>Medium</td>
                            <td>Very Good</td>
                            <td>Medium</td>
                        </tr>
                        <tr>
                            <td><strong>Full Fine-tuning</strong></td>
                            <td>10K+ examples</td>
                            <td>Days-Weeks</td>
                            <td>High</td>
                            <td>Excellent</td>
                            <td>Low</td>
                        </tr>
                    </tbody>
                </table>

                <h4>üîß AWS Fine-tuning Implementation</h4>
                <div class="concept-grid">
                    <div class="concept-card">
                        <h5>Amazon Bedrock Custom Models</h5>
                        <p>Managed fine-tuning service for supported foundation models</p>
                        <p><strong>Supported Models:</strong> Amazon Titan, select third-party models</p>
                        <p><strong>Process:</strong> Upload data ‚Üí Configure training ‚Üí Monitor progress ‚Üí Deploy</p>
                        <p><strong>Benefits:</strong> Fully managed, no infrastructure setup, automatic deployment</p>
                        <p><strong>Limitations:</strong> Limited model selection, less customization</p>
                    </div>
                    <div class="concept-card">
                        <h5>SageMaker Training Jobs</h5>
                        <p>Full control over training process with custom environments</p>
                        <p><strong>Capabilities:</strong> Any model, custom training scripts, distributed training</p>
                        <p><strong>Instance Types:</strong> ml.p4d, ml.p5, ml.trn1 for large model training</p>
                        <p><strong>Features:</strong> Spot instances, checkpointing, hyperparameter tuning</p>
                        <p><strong>Complexity:</strong> Requires ML engineering expertise</p>
                    </div>
                    <div class="concept-card">
                        <h5>SageMaker JumpStart</h5>
                        <p>Pre-configured training environments for popular models</p>
                        <p><strong>Models Available:</strong> LLaMA, Falcon, FLAN-T5, and many others</p>
                        <p><strong>Features:</strong> One-click deployment, example notebooks, PEFT support</p>
                        <p><strong>Benefits:</strong> Reduced setup time, proven configurations</p>
                        <p><strong>Use Cases:</strong> Rapid prototyping, standard fine-tuning workflows</p>
                    </div>
                    <div class="concept-card">
                        <h5>Data Preparation Considerations</h5>
                        <p>Critical factors for successful fine-tuning</p>
                        <p><strong>Quality:</strong> High-quality, relevant examples</p>
                        <p><strong>Quantity:</strong> Sufficient data for the chosen approach</p>
                        <p><strong>Format:</strong> Consistent input-output pairs</p>
                        <p><strong>Diversity:</strong> Representative of target use cases</p>
                    </div>
                </div>

                <div class="highlight-box">
                    <h4>üí° Fine-tuning Best Practices</h4>
                    <ul>
                        <li><strong>Start Small:</strong> Begin with in-context learning or RAG before committing to fine-tuning</li>
                        <li><strong>Data Quality:</strong> Invest in high-quality, diverse training data</li>
                        <li><strong>Evaluation:</strong> Set up robust evaluation metrics before training</li>
                        <li><strong>Monitoring:</strong> Track training progress and model performance</li>
                        <li><strong>Version Control:</strong> Maintain versions of models, data, and configurations</li>
                        <li><strong>Cost Management:</strong> Use spot instances and efficient training strategies</li>
                    </ul>
                </div>

                <div class="aws-services">
                    <h4>üîß AWS Services for Model Training</h4>
                    <div class="service-grid">
                        <div class="service-item">
                            <strong>Amazon Bedrock</strong><br>
                            Managed fine-tuning for supported foundation models
                        </div>
                        <div class="service-item">
                            <strong>SageMaker Training</strong><br>
                            Fully customizable training environment with distributed capabilities
                        </div>
                        <div class="service-item">
                            <strong>SageMaker JumpStart</strong><br>
                            Pre-configured training for popular open-source models
                        </div>
                        <div class="service-item">
                            <strong>S3</strong><br>
                            Storage for training data, model artifacts, and checkpoints
                        </div>
                        <div class="service-item">
                            <strong>EC2 Instances</strong><br>
                            GPU and specialized compute for model training
                        </div>
                        <div class="service-item">
                            <strong>CloudWatch</strong><br>Monitoring and evaluation metrics for training jobs
                        </div>
                    </div>
                </div>

                <div class="hands-on">
                    <h4>üõ†Ô∏è Hands-On Practice</h4>
                    <ul>
                        <li><strong>Bedrock Custom Models:</strong> Explore fine-tuning options in Bedrock</li>
                        <li><strong>SageMaker Training:</strong> Set up a training job for a foundation model</li>
                        <li><strong>Data Preparation:</strong> Format and prepare data for fine-tuning</li>
                        <li><strong>Cost Estimation:</strong> Calculate costs for different fine-tuning approaches</li>
                        <li><strong>Evaluation Setup:</strong> Create evaluation metrics and test sets</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="study-tips">
            <h4>üí° Study Tips for Domain 3</h4>
            <ul>
                <li><strong>Focus on Highest Weight:</strong> This is 28% of the exam - spend the most time here</li>
                <li><strong>Hands-On Practice:</strong> Extensive hands-on with Bedrock and SageMaker</li>
                <li><strong>Prompt Engineering:</strong> Practice with different prompt techniques extensively</li>
                <li><strong>Architecture Patterns:</strong> Understand when to use RAG vs fine-tuning vs in-context learning</li>
                <li><strong>Real Projects:</strong> Build end-to-end applications using foundation models</li>
                <li><strong>AWS Services Deep Dive:</strong> Know Bedrock and SageMaker capabilities in detail</li>
            </ul>
        </div>

        <div class="nav-buttons">
            <button class="nav-btn" onclick="window.location.href='domain2-study-guide.html'">‚Üê Previous Domain</button>
            <button class="nav-btn" onclick="window.location.href='domain4-study-guide.html'">Next Domain ‚Üí</button>
        </div>
        <div style="text-align: center; margin-top: 20px;">
            <button class="nav-btn" onclick="window.location.href='index.html'" style="background: linear-gradient(135deg, #495057, #6c757d);">üè† Back to Home</button>
        </div>
    </div>

    <script>
        function toggleTask(taskId) {
            const content = document.getElementById(taskId);
            const toggleBtn = document.getElementById('toggle' + taskId.slice(-1));
            
            if (content.classList.contains('active')) {
                content.classList.remove('active');
                toggleBtn.classList.remove('active');
            } else {
                content.classList.add('active');
                toggleBtn.classList.add('active');
            }
            
            updateProgress();
        }

        function updateProgress() {
            const totalTasks = 3;
            const activeTasks = document.querySelectorAll('.task-content.active').length;
            const progressPercent = (activeTasks / totalTasks) * 100;
            document.getElementById('progressFill').style.width = progressPercent + '%';
        }

        document.addEventListener('DOMContentLoaded', function() {
            toggleTask('task1');
        });

        document.querySelectorAll('.task-header').forEach(header => {
            header.addEventListener('click', function() {
                setTimeout(() => {
                    this.scrollIntoView({ behavior: 'smooth', block: 'start' });
                }, 100);
            });
        });
    </script>
</body>
</html>
